{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3691e2fe",
   "metadata": {},
   "source": [
    "# Spotify Recommendation System\n",
    "#### Introduction\n",
    "This notebook provides the code snippets, instructions, and descriptions of creating a Spotify recommendation system with Python. Clustering, an unsupervised machine learning algorithm, is incorporated into this project to split the dataset into clusters and reduce the processing time of the distance formula. The data used in this project is a large collection of songs from Spotify containing basic information about the track as well as numerical features derived from Spotify's API. These numerical features include interesting factors such as danceability, energy, speechiness, etc. and these factors will be used to find other similar songs. The goal of this recommendation algorithm is to find similar songs using only the numerical features provided by Spotify and does not include categorical variables such as artist or album. \n",
    "\n",
    "Things you need before you start:\n",
    "- Download Spotify 1.2m+ Songs dataset from Kaggle: https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs?reso=\n",
    "- A Spotify account (free or premium) \n",
    "- Sign up for Spotify For Developers with your personal Spotify account (https://developer.spotify.com/discover/), create a new app, and retrieve your client id and secret client id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5fe3c3",
   "metadata": {},
   "source": [
    "### Set up\n",
    "Install packages as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075fa938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from scipy.spatial.distance import cdist\n",
    "import difflib\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# to plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f0c8f",
   "metadata": {},
   "source": [
    "### Uploading the dataset\n",
    "This dataset found on Kaggle contains over 1.2 million Spotify songs. Download the datset at https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs?reso="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa64658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset from local file\n",
    "# data downloaded from https://www.kaggle.com/datasets/rodolfofigueroa/spotify-12m-songs?reso=\n",
    "spotify = pd.read_csv(r'<insert local directory of dataset>')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116ba0ff",
   "metadata": {},
   "source": [
    "### Exploratory Analysis and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2af60",
   "metadata": {},
   "source": [
    "##### Feature Descriptions\n",
    "Here are descriptions for each of the 24 features in this dataset:\n",
    "- **id**: this is the unique id given to a song by Spotify (categorical)\n",
    "- **name**: name of the song (categorical)\n",
    "- **album**: the album the song is from (categorical)\n",
    "- **album_id**: unique id given to each album by Spotify (categorical)\n",
    "- **artists**: a list of the artists from each song (categorical)\n",
    "- **artist_ids**: a list of the unique ids given to each artist by Spotify (categorical)\n",
    "- **track_number**: the track number of the song i.e. where it appears on the album (categorical - ordinal)\n",
    "- **disc_number**: disc number the song appears on (categorical - ordinal)\n",
    "- **explicit**: whether or not the song is explicit, False for not explicit, True for explicit (categorical)\n",
    "- **danceability**: measure of how dancable the song is on a contiuous scale 0-1, 0 being not danceable and 1 being the most danceable (numerical)\n",
    "- **energy**: measure of intensity/activeness of a song on a continuous scale 0 to 1, 0 being low energy and 1 being high energy (numerical)\n",
    "- **key** integer scale 0 to 11, each correspondinng to a musical key in order of stand pitch class notation - 0 = C, 1 = C#/Db, 2 = D, and so on (categorical mapped to integers)\n",
    "- **loudness**: describes loudness of a song in decibels ranging from -60 to 7.23 (numerical)\n",
    "- **mode**: whether the song is in major or minor mode, 0 for minor, 1 for major (categorical mapped to integers)\n",
    "- **speechiness**: proportion of spoken words in a track ranging from 0 to 1 (numerical)\n",
    "- **acousticness**: a continuous confidence measure if a song is acoustic ranging from 0 to 1, 0 is likely not acoustic, 1 is likely acoustic (numerical)\n",
    "- **instrumentalness**: proportion of instrumental parts of a song ranging from 0 to 1, 0 for less instrumentals and 1 for more instrumentals (numerical)\n",
    "- **liveness**: probability that a track was performed live (detects for live audience sounds) ranging from 0 to 1, 0 is not likely performed live, 1 is likely performed live\n",
    "- **valence**: measure of positivity ranging from 0 to 1, 0 for not very postive and 1 for very postive (numerical)\n",
    "- **tempo**: overall tempo of a track in beats per minute (BPM) ranging from 0 to 249 (numerical)\n",
    "- **duration_ms**: the length of a song in milliseconds (numerical)\n",
    "- **time_signature**: the overall time signature of a track in notational convention that measures how many beats per bar (numerical)\n",
    "- **year**: year song was released (categorical)\n",
    "- **release_date**: full release date of a song in YYYY-MM-DD format (categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c788db",
   "metadata": {},
   "source": [
    "Below shows a snippet of what the dataset looks like. We can see a few of the tracks in the dataset and their features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29925371",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889c70d",
   "metadata": {},
   "source": [
    "Here we return some of the information about the dataset including the size of the dataset and feature name, type, and non-null count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a5dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ce4aa",
   "metadata": {},
   "source": [
    "This will give us the count, mean, standard devaition, min, Q1, median, Q3, and max of each of the numeric columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7a2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2d26c",
   "metadata": {},
   "source": [
    "Now we will plot the frequency of values in each of our numerical datasets using histograms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536ebc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cc2b25",
   "metadata": {},
   "source": [
    "##### Exploratory Analysis Summary\n",
    "Fortunately, this data looks very clean! There are some interesting distributions shown in the plot of histograms where some are skewed and some are normal. There are no missing values and many of the features are already scaled 0 to 1. Adding a standard scalar to our clustering pipeline should be sufficient to deal with any numerical data that is not already between 0 and 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c296ec",
   "metadata": {},
   "source": [
    "##### Data Cleaning\n",
    "For cleaning, all we will being doing is creating a another dataframe containing only the numerical values. This is for the purpose of clustering with numerical audio features that are available on the Spotify API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4dfe1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate numerical values\n",
    "spotify_metrics = spotify.iloc[:, 9:22]\n",
    "list(spotify_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800f7bb",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "The unsupervised machine learning algorithm clustering will be used in this project to reduce the processing time of the distance algorithm. This works by sorting the data into groups of other 'nearby' data. The distance formula will then only search within the input song's cluster rather than the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c143b24",
   "metadata": {},
   "source": [
    "##### KMeans\n",
    "We will be using a KMeans clustering algorithm on this data because this particular algorithm works well with large datasets. We will start with 10 clsuters to see how it does, and then search through different numbers of clusters to see what performs best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3790c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans algorithm with 10 clusters to start\n",
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                                 ('kmeans', KMeans(n_clusters=10))\n",
    "                                 ], verbose=False)\n",
    "number_cols = list(spotify_metrics.columns)\n",
    "kmeans10 = song_cluster_pipeline.fit(spotify_metrics)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(spotify_metrics)\n",
    "spotify['cluster_label'] = song_cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54948a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the inertia (we want a low number)\n",
    "kmeans10['kmeans'].inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cdc767",
   "metadata": {},
   "source": [
    "Next, we will visualize these clusters on the dataset. Since there are so many features we will perform a Principle Component Analysis to project the dataset down to 2 components, and then plot a scatterplot of these two components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0502aa5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform a PCA on the features so we can visualize the results of the clustering\n",
    "# by projecting the features to 2 components\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(spotify_metrics)\n",
    "projection = pd.DataFrame(columns=['x','y'], data=song_embedding)\n",
    "projection['title'] = spotify['name']\n",
    "projection['cluster'] = spotify['cluster_label']\n",
    "\n",
    "cluster_plot = projection.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4, figsize=(12,12),\n",
    "                              c=\"cluster\", cmap=plt.get_cmap(\"jet\",10), sharex=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca821d7",
   "metadata": {},
   "source": [
    "It looks as though there are some definitive clusters in the dataset. It is a bit muddy in places, particularly because of the projection. Let's try other numbers of clusters and compare their inertias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb61b95",
   "metadata": {},
   "source": [
    "##### Finding optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3bb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit kmeans models with 1-15 clusters and plot inertia vs number of clusters\n",
    "# NOTE: this may take some time to run\n",
    "kmeans_per_k = [KMeans(n_clusters=k, random_state=42).fit(spotify_metrics)\n",
    "               for k in range (1,16)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "\n",
    "plt.figure(figsize=(8,3.5))\n",
    "plt.plot(range(1,16), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.annotate('Elbow',\n",
    "            xy=(5,inertias[4]),\n",
    "            xytext=(0.55,0.55),\n",
    "            textcoords='figure fraction',\n",
    "            fontsize=16,\n",
    "            arrowprops=dict(facecolor='black', shrink=0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6d6210",
   "metadata": {},
   "source": [
    "Our comparison of inertias for clusters 1-15 shows a very nice curve demonstrating the tradeoff of inertia and number of clusters. Five clusters appears to be where the \"elbow\" occurs and has the best tradeoff of inertia for number of clusters. Let's more closely examine how k=5 performs for our clustering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff4110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot best number of clusters (k=5)\n",
    "song_cluster_pipeline = Pipeline([('scaler', StandardScaler()),\n",
    "                                 ('kmeans', KMeans(n_clusters=5))\n",
    "                                 ], verbose=False)\n",
    "number_cols = list(spotify_metrics.columns)\n",
    "kmeans5 = song_cluster_pipeline.fit(spotify_metrics)\n",
    "song_cluster_labels = song_cluster_pipeline.predict(spotify_metrics)\n",
    "spotify['cluster_label'] = song_cluster_labels\n",
    "\n",
    "pca_pipeline = Pipeline([('scaler', StandardScaler()), ('PCA', PCA(n_components=2))])\n",
    "song_embedding = pca_pipeline.fit_transform(spotify_metrics)\n",
    "projection = pd.DataFrame(columns=['x','y'], data=song_embedding)\n",
    "projection['title'] = spotify['name']\n",
    "projection['cluster'] = spotify['cluster_label']\n",
    "\n",
    "cluster_plot = projection.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4, figsize=(12,12),\n",
    "                              c=\"cluster\", cmap=plt.get_cmap(\"jet\",5), sharex=False, colorbar = True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdde8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_plot, fig = plt.subplots()\n",
    "\n",
    "#data = np.clip(randn(250, 250), -1, 1)\n",
    "\n",
    "cax = cluster_plot.imshow(projection, cmap=plt.get_cmap(\"jet\",5))\n",
    "ax.set_title('Gaussian noise with vertical colorbar')\n",
    "\n",
    "# Add colorbar, make sure to specify tick locations to match desired ticklabels\n",
    "cbar = fig.colorbar(cax, ticks=[1,2,3,4,5])\n",
    "#cbar.ax.set_yticklabels(['< -1', '0', '> 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992c0ef7",
   "metadata": {},
   "source": [
    "The clusters in this plot look to be fairly defined, and the areas that are not as defined as likely due to the projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a40bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the inertia (we want a low number)\n",
    "kmeans5['kmeans'].inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdccc188",
   "metadata": {},
   "source": [
    "The next plots separate the clusters so we can see the whole cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1769faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "color_jet = plt.get_cmap(\"jet\",5)\n",
    "\n",
    "plt.subplot(321)\n",
    "projection0 = projection.query(\"cluster == 0\")\n",
    "plt.scatter(projection0['x'], projection0['y'], alpha = 0.4, s = 2,\n",
    "            color = color_jet(0))\n",
    "plt.axis([-5, 8, -8, 20])\n",
    "#projection0.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4)\n",
    "plt.title(\"Cluster 0\")\n",
    "\n",
    "plt.subplot(322)\n",
    "projection1 = projection.query(\"cluster == 1\")\n",
    "plt.scatter(projection1['x'], projection1['y'], alpha = 0.4, s = 2,\n",
    "            color = color_jet(0.2))\n",
    "plt.axis([-5, 8, -8, 20])\n",
    "#projection1.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4)\n",
    "plt.title(\"Cluster 1\")\n",
    "\n",
    "plt.subplot(323)\n",
    "projection2 = projection.query(\"cluster == 2\")\n",
    "plt.scatter(projection2['x'], projection2['y'], alpha = 0.4, s = 2,\n",
    "            color = color_jet(0.4))\n",
    "plt.axis([-5, 8, -8, 20])\n",
    "#projection2.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4)\n",
    "plt.title(\"Cluster 2\")\n",
    "\n",
    "plt.subplot(324)\n",
    "projection3 = projection.query(\"cluster == 3\")\n",
    "plt.scatter(projection3['x'], projection3['y'], alpha = 0.4, s = 2,\n",
    "            color = color_jet(0.6))\n",
    "plt.axis([-5, 8, -8, 20])\n",
    "#projection3.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4)\n",
    "plt.title(\"Cluster 3\")\n",
    "\n",
    "plt.subplot(325)\n",
    "projection4 = projection.query(\"cluster == 4\")\n",
    "plt.scatter(projection4['x'], projection4['y'], alpha = 0.4, s = 2,\n",
    "            color = color_jet(0.8))\n",
    "plt.axis([-5, 8, -8, 20])\n",
    "#projection4.plot(kind=\"scatter\", x=\"x\", y=\"y\", alpha=0.4)\n",
    "plt.title(\"Cluster 4\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22450c",
   "metadata": {},
   "source": [
    "### Recommendation System\n",
    "This recommendation system will be utilizing Spotify's API and the package `spotipy`. Our clustering algorithm can help reduce the computational time by only checking the similarities within the input song's cluster.\n",
    "\n",
    "This recommendation will make use of the cosine similarity formula, which is commonly used for recommendation systems. Cosine similarity measures the cosine angle between sequences of numbers as vectors. \n",
    "\n",
    "Any song found on Spotify can be input into this algorithm whether it is in the existing data or not. The recommended songs, however, are currently limited to what is in this dataset.\n",
    "\n",
    "To use this code, you will need a Spotify account (free or premium both work) and sign up for Spotify for Developers. You will then create a new app, and add your client id and client secret id to the environment variables. \n",
    "\n",
    "```\n",
    "os.environ['SPOTIFY_CLIENT_ID'] = 'your_client_id'\n",
    "os.environ['SPOTIFY_CLIENT_SECRET'] = 'your_client_secret_id'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89580c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in with your Spotify for Developers app information as detailed above\n",
    "os.environ['SPOTIFY_CLIENT_ID'] = 'your_client_id'\n",
    "os.environ['SPOTIFY_CLIENT_SECRET'] = 'your_client_secret_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cd520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input your unique authenticating information to utilize the Spotify API\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=os.environ[\"SPOTIFY_CLIENT_ID\"],\n",
    "                                                           client_secret=os.environ[\"SPOTIFY_CLIENT_SECRET\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d1385",
   "metadata": {},
   "source": [
    "The function below will retrieve the input song info. To input a song, choose a song from Spotify and copy the song URL from Spotify. You can do this by clicking the 3 dots to the right of a song -> Share -> Copy Song Link. Input the URL as a string.\n",
    "\n",
    "This function will first search the dataset for the song. If the song is not in the dataset, then it will call the Spotify API to retrieve the song information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01880c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that will retrieve song info from song URL\n",
    "# You can copy a song URL from spotify and save it as a string\n",
    "def get_song_info(URL, data = spotify):\n",
    "  id = URL.split('/')[-1].split(\"?\")[0]\n",
    "  song_in_dataset = data.loc[(data['id'] == id)]\n",
    "  new_song = []\n",
    "  scaler = song_cluster_pipeline.steps[0][1]\n",
    "\n",
    "  if song_in_dataset.empty:\n",
    "    new_song = pd.DataFrame(sp.audio_features(id))\n",
    "    new_song_metrics = new_song.drop(columns = ['type', 'id', 'uri',\n",
    "                                                'track_href','analysis_url'])\n",
    "    new_song['cluster_label'] = kmeans5['kmeans'].predict(scaler.transform\n",
    "                                                          (new_song_metrics))[0]\n",
    "    new_song['name'] = sp.track(id)[\"name\"]\n",
    "    new_song['album'] = sp.track(id)[\"album\"][\"name\"]\n",
    "    return new_song\n",
    "\n",
    "  else:\n",
    "    return song_in_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1080046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function on Lost by Frank Ocean\n",
    "LostFrankOcean = 'https://open.spotify.com/track/3GZD6HmiNUhxXYf8Gch723?si=8a7c6b5e1e1b4c78'\n",
    "get_song_info(LostFrankOcean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcefe986",
   "metadata": {},
   "source": [
    "Our last function will be the actual song recommender. It takes in the song URL as a string and will return the top 5 most similar songs as recommendations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a69517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our final function that will give song recommendations given a song\n",
    "# list, our dataset, and the number of songs to return\n",
    "def recommend_songs(URL, data = spotify, n_songs=10):\n",
    "    number_cols = list(spotify_metrics)\n",
    "    song = get_song_info(URL)\n",
    "    metadata_cols = ['name', 'year', 'artists']\n",
    "\n",
    "    # filter data by predicted cluster in song\n",
    "    clustered_data = data.loc[(data['cluster_label'] == song['cluster_label'][0])]\n",
    "\n",
    "    # scale data and new song\n",
    "    scaler = song_cluster_pipeline.steps[0][1]\n",
    "    scaled_data = scaler.transform(clustered_data[number_cols])\n",
    "    scaled_song = scaler.transform(song[number_cols])\n",
    "\n",
    "    # find the distances and the indices of the most similar songs\n",
    "    distances = cdist(scaled_song, scaled_data, 'cosine')\n",
    "    index = list(np.argsort(distances)[:, :n_songs][0])\n",
    "    \n",
    "    # collect the recommended songs\n",
    "    rec_songs = clustered_data.iloc[index]\n",
    "    rec_songs = rec_songs[~rec_songs['name'].isin(song['name'])]\n",
    "    return rec_songs#[metadata_cols].to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97055e",
   "metadata": {},
   "outputs": [],
   "source": [
    "LostFrankOcean = 'https://open.spotify.com/track/3GZD6HmiNUhxXYf8Gch723?si=8a7c6b5e1e1b4c78'\n",
    "rec_songs = recommend_songs(LostFrankOcean)\n",
    "rec_songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffc0d78",
   "metadata": {},
   "source": [
    "### Final Discussion\n",
    "So that concludes our Spotify recommendation system! Whether or not the recommendations are good are up to the individual user. Personally, I have found some interesting new songs from this that I probably would not have found otherwise. I believe that excluding features such as artist and album allow for the recommendations to focus more on how the composition of the song is similar as opposed to limiting recommendations by common categorical variables. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
